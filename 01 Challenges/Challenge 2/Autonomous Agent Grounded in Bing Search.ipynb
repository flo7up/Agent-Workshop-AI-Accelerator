{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Important Notes!!! \n",
    "- For this challenge you need to go to Azure AI Foundry portal and add a Bing Ressource as a connection. The name provided in the process is the one you need to reference in your .env file.\n",
    "- Bing Groundedness only works with GPT-4o and not with GPT-4o-mini\n",
    "\n",
    "More on Grounding with Bing: https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding?tabs=python&pivots=overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any, Callable, Set\n",
    "\n",
    "# Azure AI Projects and authentication\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import FunctionTool, ToolSet, BingGroundingTool\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "# Azure Blob Storage client\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Construct the path to the .env file in the parent directory\n",
    "env_path = Path().resolve().parent.parent / \".env\"\n",
    "\n",
    "# Load environment variables from the specified .env file\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "\n",
    "# Retrieve keys from environment variables\n",
    "BING_API_KEY = os.getenv(\"BING_API_KEY\")\n",
    "PROJECT_CONNECTION_STRING = os.getenv(\"Azure_AI_PROJECT_CONNECTION_STRING\")\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "BING_CONNECTION_NAME_IN_AZURE_AI_FOUNDRY = os.getenv(\"BING_CONNECTION_NAME_IN_AZURE_AI_FOUNDRY\")\n",
    "\n",
    "if not BING_API_KEY:\n",
    "    raise ValueError(\"BING_API_KEY is not set in the .env file.\")\n",
    "if not PROJECT_CONNECTION_STRING:\n",
    "    raise ValueError(\"PROJECT_CONNECTION_STRING is not set in the .env file.\")\n",
    "if not AZURE_STORAGE_CONNECTION_STRING:\n",
    "    raise ValueError(\"AZURE_STORAGE_CONNECTION_STRING is not set in the .env file.\")\n",
    "if not BING_CONNECTION_NAME_IN_AZURE_AI_FOUNDRY:\n",
    "    raise ValueError(\"AZURE_STORAGE_CONNECTION_STRING is not set in the .env file.\")\n",
    "\n",
    "print(\"Environment variables loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create a Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AIProjectClient.from_connection_string(\n",
    "        credential=AzureCliCredential(),\n",
    "        conn_str=PROJECT_CONNECTION_STRING,\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create an Agent with the Grounding with Bing search tool enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Please note that BING_CONNECTION_NAME_IN_AZURE_AI_FOUNDRY needs to be added as a connection in Azure AI Foundry first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/subscriptions/4c9216b8-3c30-4c2f-8ced-0837fea45954/resourceGroups/basic-agent-setup-713/providers/Microsoft.MachineLearningServices/workspaces/ffollonier-rag-project-713/connections/basicbing\n"
     ]
    }
   ],
   "source": [
    "bing_connection = client.connections.get(connection_name=BING_CONNECTION_NAME_IN_AZURE_AI_FOUNDRY)\n",
    "conn_id = bing_connection.id\n",
    "\n",
    "print(conn_id)\n",
    "\n",
    "# Initialize agent bing tool and add the connection id\n",
    "bing = BingGroundingTool(connection_id=conn_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the Azure AI Agent pipeline...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 29\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create the Azure AI Projects client with a connection string and default credential.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Instructions for the agent\u001b[39;00m\n\u001b[0;32m     22\u001b[0m instructions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124mYou are a helpful agent that provides the latest news articles about AI.\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124mAlways se the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_for_relevant_news\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m function to fetch and return current AI news.\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124mThen store the news data in Azure Blob Storage using the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_news_in_blob\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m function.\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124mAt the end, summarize your thought process and store it in Azure Blob Storage using the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_thought_process_in_blob\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m function.\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Create the agent using a chosen model (e.g., gpt-4o)\u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msimple-news-agent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefinitions\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCreated agent with ID: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ffollonier\\AppData\\Local\\anaconda3\\Lib\\site-packages\\azure\\ai\\projects\\_patch.py:213\u001b[0m, in \u001b[0;36mAIProjectClient.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client1\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client2\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ffollonier\\AppData\\Local\\anaconda3\\Lib\\site-packages\\azure\\core\\_pipeline_client.py:91\u001b[0m, in \u001b[0;36mPipelineClient.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PipelineClient[HTTPRequestType, HTTPResponseType]:\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ffollonier\\AppData\\Local\\anaconda3\\Lib\\site-packages\\azure\\core\\pipeline\\_base.py:168\u001b[0m, in \u001b[0;36mPipeline.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Pipeline[HTTPRequestType, HTTPResponseType]:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ffollonier\\AppData\\Local\\anaconda3\\Lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py:257\u001b[0m, in \u001b[0;36mRequestsTransport.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequestsTransport\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ffollonier\\AppData\\Local\\anaconda3\\Lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py:278\u001b[0m, in \u001b[0;36mRequestsTransport.open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_been_opened \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession:\n\u001b[1;32m--> 278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP transport has already been closed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou may check if you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre calling a function outside of the `with` of your client creation, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor if you called `close()` on your client already.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         )\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession:\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session_owner:\n",
      "\u001b[1;31mValueError\u001b[0m: HTTP transport has already been closed. You may check if you're calling a function outside of the `with` of your client creation, or if you called `close()` on your client already."
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Prepare the tool for the Azure AI Agent service.\n",
    "# We wrap our search function in a FunctionTool and add it to a ToolSet.\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Runs the Azure AI Agent pipeline.\n",
    "\n",
    "The agent uses the Bing Search API tool to fetch the latest AI news.\n",
    "It creates a simple conversation thread where the user message triggers the tool.\n",
    "\"\"\"\n",
    "print(\"Starting the Azure AI Agent pipeline...\")\n",
    "# Create the Azure AI Projects client with a connection string and default credential.\n",
    "\n",
    "\n",
    "#<-- This is a simple agent that fetches the latest AI news. -->\n",
    "#<-- It uses the Bing Search API tool to get the news. -->\n",
    "#<-- Uncomment the rows to allow the agent store the news in Azure Blob Storage. -->\n",
    "\n",
    "# Instructions for the agent\n",
    "instructions = \"\"\" \n",
    "You are a helpful agent that provides the latest news articles about AI.\n",
    "Always se the 'search_for_relevant_news' function to fetch and return current AI news.\n",
    "Then store the news data in Azure Blob Storage using the 'store_news_in_blob' function.\n",
    "At the end, summarize your thought process and store it in Azure Blob Storage using the 'store_thought_process_in_blob' function.\n",
    "\"\"\"\n",
    "\n",
    "with client:\n",
    "    # Create the agent using a chosen model (e.g., gpt-4o)\n",
    "    agent = client.agents.create_agent(\n",
    "        model=\"gpt-4o\",\n",
    "        name=\"simple-news-agent\",\n",
    "        instructions=instructions,\n",
    "        tools=bing.definitions\n",
    "    )\n",
    "    print(f\"Created agent with ID: {agent.id}\")\n",
    "\n",
    "    # Start a new conversation thread\n",
    "    thread = client.agents.create_thread()\n",
    "    print(f\"Created thread with ID: {thread.id}\")\n",
    "\n",
    "    # Create an initial user message\n",
    "    message = client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"Show me the latest AI news.\"\n",
    "    )\n",
    "    print(f\"User message created with ID: {message.id}\")\n",
    "\n",
    "    # Process the conversation\n",
    "    run = client.agents.create_and_process_run(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=agent.id\n",
    "    )\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    else:\n",
    "        # Retrieve and log all messages from the conversation\n",
    "        messages = client.agents.list_messages(thread_id=thread.id)\n",
    "        for msg in messages[\"data\"]:\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                print(\"Assistant response:\")\n",
    "                for part in msg[\"content\"]:\n",
    "                    if part[\"type\"] == \"text\":\n",
    "                        print(part[\"text\"][\"value\"])\n",
    "\n",
    "    # Cleanup the agent after the run\n",
    "    client.agents.delete_agent(agent.id)\n",
    "    print(\"Agent deleted successfully.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
