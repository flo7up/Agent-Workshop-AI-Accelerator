{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Important Notes!!! \n",
    "- For this challenge you need to go to Azure AI Foundry portal and add a Bing Ressource as a connection. The name provided in the process is the one you need to reference in your .env file.\n",
    "- Bing Groundedness only works with GPT-4o and not with GPT-4o-mini\n",
    "\n",
    "More on Grounding with Bing: https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/bing-grounding?tabs=python&pivots=overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any, Callable, Set\n",
    "\n",
    "# Azure AI Projects and authentication\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import FunctionTool, ToolSet, BingGroundingTool\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "# Azure Blob Storage client\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Construct the path to the .env file in the parent directory\n",
    "env_path = Path().resolve().parent.parent / \".env\"\n",
    "\n",
    "# Load environment variables from the specified .env file\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "\n",
    "# Retrieve keys from environment variables\n",
    "BING_API_KEY = os.getenv(\"BING_API_KEY\")\n",
    "PROJECT_CONNECTION_STRING = os.getenv(\"Azure_AI_PROJECT_CONNECTION_STRING\")\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "BING_CONNECTION_NAME_IN_AZURE_AI_FOUNDRY = os.getenv(\"BING_CONNECTION_NAME_IN_AZURE_AI_FOUNDRY\")\n",
    "\n",
    "if not BING_API_KEY:\n",
    "    raise ValueError(\"BING_API_KEY is not set in the .env file.\")\n",
    "if not PROJECT_CONNECTION_STRING:\n",
    "    raise ValueError(\"PROJECT_CONNECTION_STRING is not set in the .env file.\")\n",
    "if not AZURE_STORAGE_CONNECTION_STRING:\n",
    "    raise ValueError(\"AZURE_STORAGE_CONNECTION_STRING is not set in the .env file.\")\n",
    "if not BING_CONNECTION_NAME_IN_AZURE_AI_FOUNDRY:\n",
    "    raise ValueError(\"AZURE_STORAGE_CONNECTION_STRING is not set in the .env file.\")\n",
    "\n",
    "print(\"Environment variables loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create a Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AIProjectClient.from_connection_string(\n",
    "        credential=AzureCliCredential(),\n",
    "        conn_str=PROJECT_CONNECTION_STRING,\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create an Agent with the Grounding with Bing search tool enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Please note that BING_CONNECTION_NAME_IN_AZURE_AI_FOUNDRY needs to be added as a connection in Azure AI Foundry first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/subscriptions/4c9216b8-3c30-4c2f-8ced-0837fea45954/resourceGroups/basic-agent-setup-713/providers/Microsoft.MachineLearningServices/workspaces/ffollonier-rag-project-713/connections/basicbing\n"
     ]
    }
   ],
   "source": [
    "bing_connection = client.connections.get(connection_name=BING_CONNECTION_NAME_IN_AZURE_AI_FOUNDRY)\n",
    "conn_id = bing_connection.id\n",
    "\n",
    "print(conn_id)\n",
    "\n",
    "# Initialize agent bing tool and add the connection id\n",
    "bing = BingGroundingTool(connection_id=conn_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the Azure AI Agent pipeline...\n",
      "Created agent with ID: asst_Sk5V7ZrjJPjzT6qXr6uZzJJH\n",
      "Created thread with ID: thread_ab7sLNEhNbjAnL1bQZsFhGUr\n",
      "User message created with ID: msg_mBBsnZn0RbeAhqMR7WXb5hEp\n",
      "Run finished with status: RunStatus.COMPLETED\n",
      "Assistant response:\n",
      "It seems there was an issue storing the information in Azure Blob Storage. Please ensure that the storage configuration is correctly set up and try again later. \n",
      "\n",
      "However, I've provided a summary of the latest AI news, including OpenAI's new model release, Tencent's AI advancements, and the expansion of OpenAI's Sora service in Europe. Let me know if there's anything else you need!\n",
      "Assistant response:\n",
      "Here are the latest developments in AI:\n",
      "\n",
      "1. **OpenAI Launches GPT-4.5 'Orion'**: OpenAI has unveiled its largest AI model to date, GPT-4.5. This model continues the trend of increasing computational power and data usage for improved performance. It's available to users of ChatGPT Pro and OpenAI's API. Although it performs better on specific benchmarks, cost and performance scalability concerns have been noted【6†source】.\n",
      "\n",
      "2. **Tencent's New AI Model**: Tencent has introduced a new AI model aimed to outperform competitors like Deepseek. This move highlights the competitive landscape in AI development, particularly among leading tech companies【3†source】.\n",
      "\n",
      "3. **Sora Video Service by OpenAI**: OpenAI's video service, Sora, has expanded its availability to Sweden, enhancing accessibility within the EU. The service, initially launched in December, represents OpenAI's foray into varied AI applications【2†source】.\n",
      "\n",
      "I will now save this information in Azure Blob Storage. Additionally, I'll summarize my thought process regarding this task.\n",
      "Agent deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Prepare the tool for the Azure AI Agent service.\n",
    "# We wrap our search function in a FunctionTool and add it to a ToolSet.\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Runs the Azure AI Agent pipeline.\n",
    "\n",
    "The agent uses the Bing Search API tool to fetch the latest AI news.\n",
    "It creates a simple conversation thread where the user message triggers the tool.\n",
    "\"\"\"\n",
    "print(\"Starting the Azure AI Agent pipeline...\")\n",
    "# Create the Azure AI Projects client with a connection string and default credential.\n",
    "\n",
    "\n",
    "#<-- This is a simple agent that fetches the latest AI news. -->\n",
    "#<-- It uses the Bing Search API tool to get the news. -->\n",
    "#<-- Uncomment the rows to allow the agent store the news in Azure Blob Storage. -->\n",
    "\n",
    "# Instructions for the agent\n",
    "instructions = \"\"\" \n",
    "You are a helpful agent that takes user questions and searches the web using Bing Search\"\"\"\n",
    "\n",
    "with client:\n",
    "    # Create the agent using a chosen model (e.g., gpt-4o)\n",
    "    agent = client.agents.create_agent(\n",
    "        model=\"gpt-4o\",\n",
    "        name=\"simple-news-agent\",\n",
    "        instructions=instructions,\n",
    "        tools=bing.definitions\n",
    "    )\n",
    "    print(f\"Created agent with ID: {agent.id}\")\n",
    "\n",
    "    # Start a new conversation thread\n",
    "    thread = client.agents.create_thread()\n",
    "    print(f\"Created thread with ID: {thread.id}\")\n",
    "\n",
    "    # Create an initial user message\n",
    "    message = client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"Show me the latest AI news.\"\n",
    "    )\n",
    "    print(f\"User message created with ID: {message.id}\")\n",
    "\n",
    "    # Process the conversation\n",
    "    run = client.agents.create_and_process_run(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=agent.id\n",
    "    )\n",
    "    print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    else:\n",
    "        # Retrieve and log all messages from the conversation\n",
    "        messages = client.agents.list_messages(thread_id=thread.id)\n",
    "        for msg in messages[\"data\"]:\n",
    "            if msg[\"role\"] == \"assistant\":\n",
    "                print(\"Assistant response:\")\n",
    "                for part in msg[\"content\"]:\n",
    "                    if part[\"type\"] == \"text\":\n",
    "                        print(part[\"text\"][\"value\"])\n",
    "\n",
    "    # Cleanup the agent after the run\n",
    "    client.agents.delete_agent(agent.id)\n",
    "    print(\"Agent deleted successfully.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
